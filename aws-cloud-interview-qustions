1))) About CloudFront Distribution
Ans: 
 1. Signed URLs or Signed Cookies (Restrict by User Identity & Time)
    üîπ Two options:
    Signed URLs ‚Äì Restrict access to specific files.
    Signed Cookies ‚Äì Grant access to multiple files or an entire path.
    üîê How it works:
    Create a CloudFront key pair under your AWS account.
    Use that key pair to sign URLs or cookies.
    Distribute the signed URL/cookie to users who are allowed access.
    CloudFront validates the signature and only serves content if valid.
    Use Cases:
    Pay-per-view content
    Temporary access to private files.

2.  Restrict Access by Geographic Location (Geo Restriction)
    Goal: Allow or block users based on their geographic location (country).
    Go to CloudFront ‚Üí your distribution ‚Üí Restrictions tab ‚Üí Geo restriction.
    Choose ‚ÄúAllowlist‚Äù or ‚ÄúBlocklist‚Äù specific countries.

3. Restrict S3 Access Using Origin Access Control (OAC) or Origin Access Identity (OAI)
  üîπ Purpose:
  Prevent direct access to your S3 bucket content. Only CloudFront should be able to fetch and serve files.
  üîπ OAC (Origin Access Control) - Recommended
  A newer and more flexible way than OAI to securely allow CloudFront to access S3.
  üõ†Ô∏è Steps to Implement OAC:
  Create a CloudFront distribution.
  Choose S3 as the origin.
  Enable Origin Access Control in the origin settings.
  Set the S3 bucket policy to allow access only from CloudFront via the OAC.


4. What Is a Cache Policy in CloudFront?
   A Cache Policy in Amazon CloudFront defines how CloudFront caches content at edge locations based on specific request attributes, such as:
   Query strings (e.g., ?user=123)
   Headers (e.g., Authorization, Accept-Encoding)
   Cookies (e.g., session IDs)
   Request body (for POST requests, rarely used)

   1. TTL Settings (Time To Live)
      Determines how long content stays in CloudFront's cache.

   2. Cache Key Settings
      The cache key is the unique ID used to store and retrieve objects from the cache. You define what parts of the viewer request are included in this key.
      You can include:
      ‚úÖ Query Strings
      Cache different versions of a URL based on query string parameters.
      Example: ?color=red vs ?color=blue


5. üõ°Ô∏è What is AWS WAF?
   AWS WAF (Web Application Firewall) is a security service that helps protect your web applications from:
   Common web exploits (SQL injection, XSS)
   Bot traffic and DDoS attacks (A Distributed Denial-of-Service (DDoS) attack is a cyberattack that uses multiple 
   compromised computers (a botnet) to overwhelm a target website, server, or network with traffic, 
   making it unavailable to legitimate users)
   Bad IPs or countries
   Custom threats defined by request patterns
   It filters and monitors HTTP/HTTPS traffic to your applications based on rules you define.

     üß† How It Works (Request Flow)
     A user sends a request to your application (e.g., via CloudFront or ALB).
     AWS WAF intercepts the request before it reaches your app.
     WAF evaluates the request against your defined rules in the Web ACL.
     Based on matching rules, it takes an action:
     ‚úÖ Allow
     ‚ùå Block
     üîç Count (for testing rules without enforcement)



‚úÖ 1. Amazon EBS (Elastic Block Store)
üîπ What is EBS?
Amazon EBS is block-level storage used with EC2 instances.
It provides durable, high-performance storage volumes that persist independently from EC2 instance life cycles.
Think of it as a virtual hard drive attached to your EC2 instance.
üîπ Use Cases:
Hosting databases, file systems, container storage.
Running enterprise applications like SAP, Oracle DB, etc.
üîπ Limitations:
Tied to an Availability Zone (AZ) ‚Äî cannot be accessed from multiple AZs directly.
Must attach/detach manually between EC2s.
üîπ Interview Tip:
If asked to explain EBS, say:
"EBS is a block-level storage designed for EC2 instances. It's ideal for low-latency workloads 
 like databases. It allows snapshotting, resizing, and supports multiple volume types for performance tuning."


‚úÖ 2. Amazon EFS (Elastic File System)
üîπ What is EFS?
EFS is a fully managed NFS (Network File System) for EC2 and container workloads.
It‚Äôs shared, scalable, and POSIX-compliant ‚Äî suitable for Linux-based applications that need a distributed file system.
üîπ Key Features:
Shared Access: Can be mounted on multiple EC2 instances across AZs simultaneously.
Scalable: Automatically scales storage as you add/remove files ‚Äî up to petabyte scale.
üîπ Use Cases:
Web servers, shared home directories, CI/CD pipelines, CMS platforms, container storage in EKS/ECS.
üîπ Interview Tip:
"EFS is a scalable, shared file system suitable for Linux-based EC2 instances and containers. 
 It‚Äôs great for scenarios where multiple compute resources need concurrent access to the same data."


4. You need to share large files (like media assets or reports) securely with external users. How would you do that using AWS services?
‚úÖ Ideal Answer:
I‚Äôd upload the files to Amazon S3 and generate pre-signed URLs that provide temporary, 
time-limited access to those objects. This ensures the file is publicly accessible only through 
the signed URL and not exposed to unauthorized users.


5. Your team needs to mount a file system that is accessible by containers running in Amazon ECS or EKS. Which storage solution fits this use case?
‚úÖ Ideal Answer:
Amazon EFS is the best fit here. It integrates well with Amazon ECS (via EFS Volume configuration) and EKS (via CSI drivers), 
allowing containers to share a persistent file system. It supports multi-AZ and scales automatically, 
which suits dynamic container workloads.


6. How would you perform a backup of an EC2 instance?
‚úÖ Ideal Answer:
I would take a snapshot of the EBS volume attached to the instance. Snapshots are incremental and stored in S3, 
allowing for efficient, version-controlled backups. These snapshots can also be used to create new EBS volumes or 
restore the instance in another region/AZ.



7. Your EC2 instance has crashed, and you need to recover the data stored on it. What steps do you take?
‚úÖ Ideal Answer:
Since EBS volumes are independent of EC2 instances, I‚Äôd:
Detach the EBS volume from the failed instance (if not automatically detached).
Attach the volume to a new EC2 instance in the same AZ.
Mount the volume and access the data.
If a snapshot exists, I can also create a new EBS volume from that snapshot and attach it to any instance.


8).
| Aspect      | Identity-based Policy                                        | Resource-based Policy                                                                      |
| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------ |
| Attached to | IAM Users, Groups, Roles                                     | AWS Resources (like S3 Buckets, Lambda, etc.)                                              |
| Controls    | What *actions* the identity can perform on *which resources* | Who can access the *resource* and what actions they can perform                            |
| Example     | A policy that allows a user to access `my-bucket`            | A bucket policy that allows a specific IAM role from another 
                                                                               account to access `my-bucket`


üî∏ Example Use Case: Accessing an S3 Bucket
Let‚Äôs assume:
You have an S3 bucket called my-company-logs.
You want to allow:
Your own IAM users to read and write logs.
A user/role from another AWS account (cross-account access) to write logs.

‚úÖ Identity-based Policy Alone (For Same Account)

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": ["s3:GetObject", "s3:PutObject"],
      "Resource": "arn:aws:s3:::my-company-logs/*"
    }
  ]
}


‚ùå Limitation: Cross-Account Access Not Possible with Only Identity-based Policies
Suppose another AWS account (Account B) needs to write logs to your S3 bucket (owned by Account A). 
The identity-based policy on Account B‚Äôs IAM role is not enough.

Even if Account B's role has a policy like:
{
  "Effect": "Allow",
  "Action": "s3:PutObject",
  "Resource": "arn:aws:s3:::my-company-logs/*"
}
It won‚Äôt work unless your S3 bucket explicitly allows access via a resource-based policy.


‚úÖ Why Use Resource-based Policy? (S3 Bucket Policy)
To allow cross-account access, you must attach a resource-based policy (bucket policy) like this:
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::123456789012:role/CrossAccountLogWriter"
      },
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::my-company-logs/*"
    }
  ]
}
This says:
‚ÄúThe IAM role from Account B is allowed to write to my bucket.‚Äù

















     




   
