1) What is a Jenkins pipeline?
Ans: It is pack of plugins and intigarions of tools such as git, maven, sonar, docker, k8s  
that supports integrating and implementing continuous delivery pipelines using code.

2) What is the difference between freestyle project and pipeline?
Ans: Freestyle: UI-based and limited customization. Pipeline: Scripted and supports complex workflows as code.

1. Freestyle Project
A Freestyle Project in Jenkins is a simple, GUI-based job where you configure everything using forms and dropdowns.
ğŸ”¹ Key Points:
Created using UI â€” no code needed.
You define steps like: source code checkout, build commands, test execution, and deployment manually in the Jenkins dashboard.
Easy to set up for simple CI/CD workflows.
Not easily portable or reusable â€” if you want to replicate it, you need to manually recreate or copy the job.
Harder to maintain for large or complex projects.



ğŸ’¡ Example:
A Freestyle project might pull code from GitHub, run a Maven build, and then deploy an artifact to a server â€” all configured through the Jenkins web interface.

2. Pipeline Project
A Pipeline Project uses code (Jenkinsfile) to define the entire CI/CD workflow in a script.
ğŸ”¹ Key Points:
Pipeline as Code â€” everything (build, test, deploy) is written in a Jenkinsfile.
Stored inside the source code repository, making it version-controlled.
Supports complex workflows like parallel builds, approvals, error handling, and environment variables.
Easier to reuse and maintain, especially for large teams or multiple environments.
Allows Groovy-based scripting for more flexibility and automation.


4) What are the types of pipelines in Jenkins?
  ans: 
  1. Declarative Pipeline
  This is the most commonly used type.
  Uses a simplified and structured syntax (introduced later to make pipelines easier to write).
  Defined inside a pipeline { } block in a Jenkinsfile.
  Easier to read and maintain; best suited for most CI/CD use cases.

  2. Scripted Pipeline
  Uses Groovy scripting syntax (older and more flexible).
  Everything is written in a script { } block.
  Gives more control and logic (like loops, conditions, custom functions), but is more complex.
  Often used when you need advanced logic or dynamic behavior in your pipeline.

  3. Multibranch Pipeline
  Automatically creates and manages pipelines for each branch in your source control repository (e.g., GitHub).
  Each branch can have its own Jenkinsfile, allowing separate build/test configurations.
  Commonly used in Git-based CI/CD where multiple teams work on different branches.

5) what is jenkins pipeline?
ANS: A Jenkinsfile is a text file that defines the CI/CD pipeline as code. 
      It contains all the build, test, and deployment stages and is stored in the source code repository, 
      allowing version control and automation of the entire workflow.


6) Where is Jenkins installed?
Ans: Jenkins is usually installed on a Linux server or as a Docker container. 
      Its main home directory is /var/lib/jenkins, where all configurations, jobs, and plugins are stored.
      The JENKINS_HOME directory stores:

      Job configurations
      Plugins
      Jobs
      Build logs
      Pipeline scripts
      User and system settings


7) How do you configure a job in Jenkins?
Ans:
  A Jenkins job (or project) defines a set of tasks (like build, test, deploy) that Jenkins should execute. 
  You can configure it either through the UI (for Freestyle jobs) or through a Jenkinsfile (for Pipeline jobs).

  To configure a Jenkins job, go to the Jenkins dashboard, click â€œNew Item,â€ choose the job type (Freestyle or Pipeline), 
  connect your source code repository, define build steps and triggers, then save and run the job. For advanced automation, 
   we use a Jenkinsfile to define everything as code.

  By creating a new job, choosing project type (freestyle/pipeline), and setting steps like source control, build steps, post-build actions.




   Login to Jenkins Dashboard
â†’ Open your Jenkins URL (e.g., http://localhost:8080)
â†’ Enter your credentials.

Create a New Job
â†’ Click on â€œNew Itemâ€
â†’ Enter a Job Name
â†’ Select â€œFreestyle projectâ€ (or â€œPipelineâ€ if you want code-based setup)
â†’ Click OK

Configure Source Code Management (SCM)
â†’ Under the Source Code Management section, select Git
â†’ Enter your repository URL and credentials.

Add Build Triggers (Optional)
â†’ You can choose how the job should start:

Build periodically (like a cron job)
Poll SCM (automatically build on code changes)
Build after another project

Add Build Steps
â†’ Under Build, click â€œAdd build stepâ€
â†’ Choose what you want Jenkins to do (e.g., â€œExecute shellâ€, â€œInvoke Gradle/Mavenâ€, etc.)
â†’ Example: mvn clean package

Add Post-Build Actions
â†’ Configure what should happen after the build, like:

Publish artifacts
Send email notifications
Deploy to server
Save and Build
â†’ Click Save
â†’ Hit â€œBuild Nowâ€
â†’ You can check console output for logs and results.


8) What is jenkins executors?
Ans:
  A Jenkins executor is a worker process that runs one build at a time on a Jenkins node. 
  The number of executors determines how many jobs can run in parallel. If all executors are busy, new builds wait in the queue.

  A Jenkins executor is basically a slot or a worker thread on a Jenkins node (master or agent) that runs your jobs.
  Think of it like this:
  Each executor is a seat where Jenkins can run one build at a time.
  If a node has 2 executors, that means it can run 2 jobs in parallel on that machine.


9) How do we trigger jenkins job automatically?
ans:
  1. Poll SCM (Source Code Management)
Jenkins regularly checks the source code repository (e.g., GitHub) for changes.
If it detects any new commits, it automatically triggers the job.

Configuration:
Go to Job â†’ Configure â†’ Build Triggers â†’ Poll SCM
Add a schedule (CRON format), for example:
H/5 * * * * 
â†’ This checks every 5 minutes.
ğŸ’¡ Note: This doesnâ€™t trigger instantly; it polls periodically.

2. Webhook (Preferred for GitHub/GitLab)
This is the most efficient and real-time way.
When you push code to GitHub, it sends a webhook to Jenkins to start the job immediately.
Setup:
In Jenkins:
Enable â€œGitHub hook trigger for GITScm pollingâ€ under Build Triggers.
In GitHub repo:
Go to Settings â†’ Webhooks â†’ Add Webhook
Add your Jenkins URL:
http://<jenkins-server>:8080/github-webhook/

Choose application/json and select â€œJust the push event.â€
ğŸ’¡ Use this for real-time CI/CD pipelines.

3. Build Periodically (Cron Job Style)
Used to trigger builds on a fixed schedule, even if no code changes happen.
Example:
H 2 * * *   â†’ runs daily at 2 AM
H/10 * * * * â†’ runs every 10 minutes
Set this under:
Build Triggers â†’ Build periodically

4. Upstream/Downstream Triggers
One Jenkins job automatically triggers another after completion.

Example:
Job A builds the code.
When Job A finishes successfully, it triggers Job B for deployment.
Set under:
Post-build Actions â†’ Build other projects

5. Trigger from Pipeline Script
You can define automatic triggers directly in your Jenkinsfile.
Example:
pipeline {
    triggers {
        cron('H/15 * * * *')  // Run every 15 minutes
    }
    stages {
        stage('Build') {
            steps {
                echo "Building..."
            }
        }
    }
}

âœ… Short Interview Answer:

We can trigger Jenkins jobs automatically using several methods â€” most commonly by Git webhooks for real-time triggers, 
Poll SCM for periodic checks, Build periodically using cron schedules, or Upstream/Downstream job dependencies. 
In pipelines, triggers can also be defined in the Jenkinsfile.



6) can you explain about upstream, down stream jobs in jenkins?
Ans:
  1. Upstream Job
    An upstream job is the job that triggers another job after it completes.
    Think of it as the source job.
    Example
    Job A builds the code â†’ after it succeeds, it triggers Job B for testing.
    Here, Job A is upstream of Job B.

  2. Downstream Job
    A downstream job is the job that gets triggered by another job.
    Think of it as the dependent job.
    Example:
    Job B runs after Job A completes â†’ Job B is downstream of Job A.

  3. How to Configure Upstream/Downstream Jobs:
  Using Post-Build Actions in Freestyle Job:
  Go to ***Job A â†’ Configure â†’ triggers â†’ Build after other projects are built ***
  Enter the downstream job name (Job B)
  Optionally choose â€œTrigger only if build is stableâ€

7) Difference between master and agent?
Ans:
1. Jenkins Master
The master is the central server that controls the Jenkins environment.
Responsibilities of Master
Manage Jenkins configuration and system settings.
Schedule jobs and assign them to agents (or run on master itself).
Monitor agents and track job execution status.
Store build history, logs, and artifacts (though agents may also store temporary artifacts).
Provide UI and API access to users.
Note: You can run small jobs on master itself, but heavy builds are usually offloaded to agents.

2. Jenkins Agent (or Slave)
An agent is a worker node that performs the actual job execution.
Responsibilities of Agent:
Executes jobs assigned by the master.
Can run multiple executors to handle parallel builds.
Can be on a different machine (Linux, Windows, Docker container).
Reports build results back to the master.

Jenkins Master is the central server responsible for scheduling jobs, managing configuration, and monitoring agents. 
Agents are worker nodes that execute jobs assigned by the master, often running on separate machines to distribute workloads efficiently.


8) How to secure Jenkins?
Ans: 

ğŸ”¹ How to Secure Jenkins

Enable Authentication
Require users to log in before accessing Jenkins.
Use Jenkinsâ€™ own user database, LDAP, Active Directory, or OAuth/GitHub authentication.
Set Proper Authorization
Control who can do what using Matrix-based security or Project-based Matrix Authorization.
Avoid giving everyone admin privileges; assign roles like Admin, Developer, or Viewer.

Use HTTPS
Enable SSL/TLS to encrypt traffic between users and Jenkins.
Can be done via reverse proxy (Nginx/Apache) or Jenkins native SSL support.
Secure Jenkins Master and Agents
Restrict network access to the Jenkins master and agents.

Only allow trusted hosts and users.
Use firewall rules or VPN.

Secure Credentials
Store passwords, tokens, and keys in Jenkins Credentials Plugin instead of hardcoding in jobs or Jenkinsfile.
Use secret text, secret files, or SSH keys.
Keep Jenkins and Plugins Updated
Regularly update Jenkins core and installed plugins to patch known vulnerabilities.
Avoid using unverified or deprecated plugins.


To secure Jenkins, we enable authentication and authorization, use HTTPS url, restrict access to the master and agents, 
store credentials securely, keep Jenkins and plugins updated, enable CSRF protection, and audit user actions. 
This ensures only authorized users can access and execute jobs safely.

Use Matrix-based security
Use Role-Based Access Control plugin


9) Explain about throttle builds?
Ans: Enforces a minimum time between builds based on the desired maximum rate.
Note: this does not enforce an "average" rate, it only looks at the time since last build.


10) How do you monitor Jenkins?
Ans: 
  a. Jenkins â€œManage Jenkinsâ€ Dashboard

Go to: Manage Jenkins â†’ System Log / Load Statistics / Manage Nodes

You can check:
Queue length and build executor utilization
Node (agent) connectivity and load
System logs and thread dumps

b. Monitoring Plugin
Plugin: Monitoring Plugin
Provides graphs for:
Memory usage (heap, non-heap)
CPU load
Thread count
HTTP sessions
Garbage collection

c. Metrics Plugin
Plugin: Metrics Plugin
Exposes JVM, system, and Jenkins metrics via REST endpoints (e.g., /metrics/)
Can be scraped by tools like Prometheus

ğŸ“Š 2. External Monitoring & Visualization
a. Prometheus + Grafana
This is the most common modern setup.
Install Prometheus Plugin on Jenkins.
Prometheus scrapes Jenkins metrics at /prometheus.
Configure Grafana dashboards using community templates to visualize:
Job success/failure rates
Build queue time
Node performance
Jenkins master health

â€œI monitor Jenkins at multiple levels â€” application health, job performance, and infrastructure â€” using 
a combination of built-in tools and external monitoring systems.
At the Jenkins level, I use the built-in dashboards under â€˜Manage Jenkinsâ€™ to check node status, 
queue length, and executor utilization. 
I also enable the Monitoring and Metrics plugins to collect detailed JVM and system-level statistics.
For advanced observability, I integrate Jenkins with Prometheus and Grafana. 
Prometheus scrapes metrics from the Jenkins /prometheus endpoint, and Grafana visualizes trends 
like build success rates, queue times, and resource usage. 
I also configure alerts in Alertmanager or Grafana to notify me of high queue times, 
frequent build failures, or node disconnections.
Additionally, Jenkins logs are shipped to an ELK stack (Elasticsearch, Logstash, Kibana) for 
centralized log analysis and troubleshooting.
On the infrastructure side, I monitor CPU, memory, and disk usage using tools 
like Node Exporter or Datadog, since Jenkins performance heavily depends on the underlying server.


11) What is a parameterized build?
ans:
    â€œIn real projects, we use parameterized builds to make Jenkins jobs flexible and reusable. 
    Instead of maintaining multiple jobs for each environment, we create a single job that takes parameters â€” 
    such as the target environment, branch, or version â€” and deploys accordingly.â€
  
    For example, you might pass parameters like a branch name, environment name, or version 
    number â€” and Jenkins uses those values during the build process.â€
    This combination gives a full picture â€” system health, job reliability, and real-time 
    alerts â€” helping maintain high CI/CD uptime and fast feedback cycles.â€

    Letâ€™s say you have a deployment job.
    Instead of creating separate jobs for dev, staging, and production, you can create one parameterized 
    job with a parameter like:
    ENVIRONMENT = dev / staging / production
    Then your build script or pipeline can use it:
    sh "deploy.sh --env=${params.ENVIRONMENT}"
    So when triggering the job manually or via another pipeline, you can choose which environment to deploy to.


12) What are shared libraries in Jenkins?

Ans: â€œIn Jenkins, a Shared Library is a way to create reusable pipeline code that can be used across multiple Jenkins jobs or projects.
Instead of writing the same pipeline logic in every Jenkinsfile â€” like build, test, deploy stages â€” 
we can define that logic once in a shared library and import it into any pipeline.

This helps maintain consistency, reduces code duplication, and makes pipeline maintenance much easier 
across large teams or multiple microservices.â€

A shared library is usually stored in a Git repository and has this structure:
(root)
 â”œâ”€â”€ vars/
 â”‚    â””â”€â”€ buildAndDeploy.groovy
 â”œâ”€â”€ src/
 â”‚    â””â”€â”€ org/company/utils/Helper.groovy
 â””â”€â”€ resources/
      â””â”€â”€ templates/


@Library('my-shared-library') _
pipeline {
  agent any
  stages {
    stage('Build & Deploy') {
      steps {
        buildAndDeploy(env: 'dev')
      }
    }
  }
}

Go to Manage Jenkins â†’ System â†’ Global Pipeline Libraries
Click Add then give name and repository url


13) What to do if Jenkins build fails suddenly?
Ans: 
â€œIf a Jenkins build fails suddenly, the first step is to analyze the cause of the failure systematically â€” 
whether itâ€™s a code issue, environment issue, or Jenkins configuration problem.

I start by checking the console output to identify at which stage the failure occurred â€” for 
example, during checkout, build, test, or deployment.

Then I verify things like:
Any recent code commits that might have broken the build
Jenkins agent/node status â€” sometimes builds fail because the agent is offline or out of disk space
Environment variables, credentials, or dependencies that might have changed
Plugin or tool updates that could have affected the job
Once I find the root cause, I fix the underlying issue â€” for example, by reverting a bad commit, 
reconfiguring the agent, or clearing workspace issues â€” and then re-trigger the build.

To prevent similar failures in the future, I also add alerting and notifications, 
improve error handling in pipelines, and, if needed, include retry mechanisms or rollback steps in the Jenkinsfile.â€


14) How to run a pipeline on multiple environments?
Ans: â€œTo run a pipeline on multiple environments in Jenkins, we typically use parameterized 
pipelines or multi-stage pipelines where each stage targets a specific environment â€” like Dev, QA, Staging, and Production.
We define an environment parameter (for example, ENV = dev / qa / prod) and then use 
that parameter inside the pipeline to decide which servers, configurations, or credentials to use.
This allows us to use one single Jenkinsfile to deploy the same application 
across multiple environments with controlled logic and approvals.
In real-time, Iâ€™ve used this approach to promote builds automatically from Dev â†’ QA â†’ Prod, 
using either manual approval steps or automated triggers after successful validation.â€
