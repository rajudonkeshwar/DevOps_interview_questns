1) What is AMI?
Ans: An AMI (Amazon Machine Image) is basically a template that contains the operating system, application server, and any software or configurations 
     needed to launch an EC2 instance. You can think of it as the "blueprint" for your virtual machines in AWS.
     When I launch an EC2 instance, I select an AMI, and that AMI determines what‚Äôs preinstalled on the instance‚Äîfor example, 
     whether it‚Äôs a Linux or Windows machine, or if it has additional software like Apache, Docker, or custom configurations.


2) What is the difference between ami and launch template?
Ans: An AMI (Amazon Machine Image) is the base image or blueprint that defines what‚Äôs inside an EC2 instance‚Äîthings like the operating system, 
     preinstalled software, and configurations. It answers the question: ‚ÄúWhat will my instance look like when it launches?‚Äù

     On the other hand, a Launch Template is a broader configuration that defines how the instance should be launched. 
     It includes not only the AMI ID but also instance type, key pair, security groups, networking settings, IAM roles, and other launch parameters.
    
    In short:
    AMI = What goes inside the instance (OS + software)
    Launch Template = How the instance is launched (AMI + instance type + networking + security + scaling configs)


3) Tell me something about EBS and EFS?
    Ans: 
    Both EBS (Elastic Block Store) and EFS (Elastic File System) are AWS storage services, but they serve different purposes.
    EBS is a block-level storage that attaches to a single EC2 instance (like a virtual hard drive). 
    It‚Äôs great for databases, applications, or workloads that need low-latency storage. 
    EBS volumes are tied to one Availability Zone, but we can take snapshots to back them up or move them.

    EFS is a fully managed network file system that can be mounted by multiple EC2 instances 
    across multiple Availability Zones at the same time. It provides shared storage, scales automatically as data grows, 
    and is ideal for scenarios like content management, big data analytics, 
    or when multiple servers need access to the same files (Web Applications with Shared Content).
    In real-time
    I‚Äôve used EBS for application servers and databases, where each instance needs its own dedicated storage.
    I‚Äôve used EFS for web applications where multiple EC2 instances (behind a load balancer) needed to share the same static content.
    So in short:
    EBS = Single-instance block storage (like a hard disk)
    EFS = Multi-instance shared file storage (like a network drive)



4) What is the difference between IAM Role and IAM User ?

Ans: An IAM User is a permanent identity created for an individual or application that needs long-term access to AWS. 
It has associated credentials like username/password or access keys. For example, 
I might create an IAM user for a developer who needs to log in to the AWS console or use CLI.

An IAM Role, on the other hand, is a temporary identity with permissions that can be assumed by AWS services, 
applications, or even users, granting them temporary security credentials to make aws api calls.
IAM roles are not directly associated with specific users or group, they are intended to be assumable by anyone
who needs them.
Roles don‚Äôt have permanent credentials; instead, they provide temporary security tokens. 
For example, an EC2 instance can assume a role to access S3 without embedding access keys.

üëâ In short:
IAM User = Long-term identity with permanent credentials
IAM Role = Temporary identity assumed by trusted entities, with no long-term credentials
In real-time, I‚Äôve used:
IAM Users for team members who need direct access with MFA.
IAM Roles for EC2, Lambda, and CI/CD pipelines to securely access resources without hardcoding credentials.


5) What are the types of storage in AWS?

ans: AWS offers different types of storage services, each designed for specific use cases:
Amazon S3 (Simple Storage Service) ‚Äì Object storage. It‚Äôs highly durable and scalable, mainly used for backups, 
static content, logs, and data lakes.
Amazon EBS (Elastic Block Store) ‚Äì Block storage. It works like a virtual hard disk for EC2 instances. 
Best for databases and applications requiring low-latency access.
Amazon EFS (Elastic File System) ‚Äì File storage. A shared file system that can be mounted across multiple EC2 instances, 
useful for content management and web apps.

6) What are the types of Load Balancers in AWS, can you explain me about them?
ans:
1. Application Load Balancer (ALB)
Operates at Layer 7 (Application Layer).
Best for web applications since it understands HTTP/HTTPS protocols.
Supports advanced routing:
Host-based routing (e.g., send traffic for api.example.com to one target group, app.example.com to another).
Path-based routing (e.g., /images goes to one service, /videos to another).
Supports SSL termination, WebSockets, HTTP/2, and integrates with ECS/EKS for containerized workloads.

‚úÖ Real-time use: I‚Äôve used ALB in a microservices architecture, where traffic was routed to different services based on URL paths. 
It helped simplify deployments and improve scalability.


2. Network Load Balancer (NLB)
Operates at Layer 4 (Transport Layer).
Designed for high-performance workloads ‚Äî handles millions of requests per second with ultra-low latency.
Supports TCP, UDP, and TLS traffic.
Provides a static IP or Elastic IP per Availability Zone, which is useful for whitelisting.
Often used for latency-sensitive applications like gaming, financial systems, or real-time communications.

‚úÖ Real-time use: I‚Äôve configured NLB for an internal payment processing system that required very low latency and high throughput.



3. Classic Load Balancer (CLB) (Legacy)
Supports both Layer 4 and Layer 7, but with limited features compared to ALB/NLB.
AWS recommends using ALB or NLB instead for new applications.
Still used in legacy environments where applications were designed around it.
‚úÖ Real-time use: I‚Äôve come across CLB mainly in older projects where migrating to ALB/NLB wasn‚Äôt immediately feasible.



4. Gateway Load Balancer (GWLB)
Operates at Layer 3 (Network Layer).
Used to deploy, scale, and manage third-party virtual appliances like firewalls, 
intrusion detection/prevention systems (IDS/IPS), and packet inspection tools.
It combines transparent network gateway and load balancing, making it easy to integrate security appliances in your traffic flow.

‚úÖ Real-time use: In one project, we used GWLB with a Palo Alto firewall appliance to inspect and filter inbound traffic 
before it reached the VPC workloads.



Summary (Quick Interview Line):
ALB ‚Üí Layer 7, intelligent routing for web/microservices.
NLB ‚Üí Layer 4, ultra-low latency, millions of requests/sec.
CLB ‚Üí Legacy, limited features.
GWLB ‚Üí Layer 3, integrates third-party security appliances.



7) What is route53?

Answer:
Amazon Route 53 is AWS‚Äôs scalable and highly available DNS (Domain Name System) service. It‚Äôs named Route 53 because DNS works on port 53.
It mainly provides three functions:
Domain Registration ‚Äì You can register and manage domain names directly in Route 53.
DNS Routing ‚Äì It maps human-readable domain names (like example.com) with IP addresses so users can connect to applications. 
It supports different routing policies such as Simple, Weighted, Latency-based, Failover, Geolocation, and Multi-value routing.
Health Checks & Monitoring ‚Äì It can check the health of endpoints and route traffic away from unhealthy resources, improving reliability.

‚úÖ Real-time use:
In one project, I used Route 53 to manage DNS for a web application hosted on EC2 and S3. 
We configured Latency-based routing so users from the US were served from the US region 
and users from Asia from the Singapore region, reducing latency.
I‚Äôve also set up failover routing with Route 53 so that if the primary web server goes down, 
traffic automatically shifts to a standby server in another region.
So, Route 53 is not just a DNS service but also plays a key role in global traffic management, 
high availability, and disaster recovery.


8) How does route53 will do health checks and monitoring?

     Answer:
Route 53 performs health checks and monitoring by continuously sending requests to your application endpoints (like a web server, database, 
or another AWS resource) from multiple AWS locations worldwide.

Here‚Äôs how it works:
Health Checks:
You define a health check in Route 53 by specifying an endpoint (IP or domain), protocol (HTTP, HTTPS, or TCP), 
and conditions (like response code or string match).
Route 53 agents in different regions send requests at regular intervals (default every 30 seconds, can be 10 seconds for fast checks).
If a majority of checkers detect failures, the endpoint is considered unhealthy.

Integration with DNS Routing:
Health checks are tied to DNS records. If a record‚Äôs target is unhealthy, 
Route 53 will automatically stop returning that endpoint in DNS responses.
This enables failover or multi-region high availability.

Alarms & Monitoring:
Health checks can be associated with CloudWatch Alarms. For example, if a health check fails, CloudWatch can trigger an SNS notification 
to alert the team.
This provides both automated failover and proactive monitoring.


9) How do you secure an S3 bucket?

ans: 
Securing an S3 bucket is one of the most important responsibilities in AWS because by default, 
S3 buckets are private, but misconfigurations can lead to data leaks. 
I usually apply a defense-in-depth approach with the following measures:

Block Public Access ‚Äì At both the account and bucket level, I enable ‚ÄúBlock Public Access‚Äù settings 
to make sure no accidental public exposure happens.

Bucket Policies and IAM Policies ‚Äì I use least-privilege permissions, granting only the required users, 
roles, or applications access to the bucket. For example, giving read-only access to an application role instead of full control.

Encryption ‚Äì I enable server-side encryption (SSE-S3 or SSE-KMS) so that all objects are encrypted at rest. 
For highly sensitive data, I use SSE-KMS with AWS KMS keys for tighter control and auditing.

I also enable versioning, so that we can manage deletion of object.

Access Logging & Monitoring ‚Äì I turn on S3 access logs or CloudTrail data events to track who is accessing the bucket. 
I also set up CloudWatch alarms to detect suspicious activity.

MFA Delete ‚Äì For critical buckets, I enable MFA Delete to protect against accidental or malicious deletion of objects.

VPC Endpoints ‚Äì I restrict S3 access so that it only comes from specific VPC endpoints, keeping traffic private and within the AWS network.

‚úÖ Real-time example:
In one project, we had an S3 bucket storing build artifacts. We secured it by applying a bucket policy 
that only allowed access from our CI/CD IAM role, enabled encryption with KMS, and restricted 
all access to our private VPC endpoint. This ensured the bucket was not accessible from the public internet.
So in short:
‚ÄúTo secure an S3 bucket, I block public access, apply least-privilege IAM and bucket policies, enable encryption, 
set up monitoring, and where required, enforce MFA Delete and VPC endpoints.‚Äù


10) What is VPC and what components does it have?
ans:

An Amazon VPC (Virtual Private Cloud) is a logically isolated network in AWS where we can launch and manage our resources securely. 
It‚Äôs like having your own private data center inside AWS, with full control over IP addressing, subnets, routing, and security.

A VPC is made up of several key components:
Subnets ‚Äì Logical divisions within a VPC, vpc can be divided in to multiple subnetworks, each associated with specific
availability zone, range ip addresses.
subnets are used to organize and segment your resources with in the vpc.

Public Subnets ‚Üí it is a subnet, it has a route to the internet through internet gateway, 
Instances launched in a public subnet can communicate directly with the internet
resources like load balancers or bastion hosts that need internet access can be launched in public subnet.

Private Subnets ‚Üí It is a subnet that does not have direct route to the internet, instances in private subnetcan communicate with
other instances with in the vpc, but inbound traffic initiated from the internet is not allowed
databases or application servers without direct internet access.

Internet Gateway (IGW) ‚Äì Allows communication between VPC resources and the internet.
It is the gateway you can add it to your vpc to enable direct connection between your resources and internet
resources that need to use the gateway for internet access must be in a public subnet, and have a public ip address

NAT Gateway / NAT Instance ‚Äì Allows instances in private subnets to the internet
this is the gateway, which is used to initiate the internet connection to the resources which are in private subnet
we can configure it through the route table by creating routes.
(e.g., for updates) without being exposed to inbound traffic.

Route Tables ‚Äì Define how traffic flows within the VPC, to subnets, internet gateway, NAT, or peered VPCs.
A route table contains a set of rules called routes, that are used to determine, where the network traffic should
be directed, each subnet in a vpc must be associated with route table which controls the trffic with in the subnet.

Security Groups ‚Äì Stateful firewalls that control inbound and outbound traffic at the instance level.

Network ACLs (Access Control Lists) ‚Äì Stateless firewalls that control traffic at the subnet level.

VPC Peering / Transit Gateway ‚Äì Enables communication between multiple VPCs, either within the same account or across accounts.
It is a networking connection between two virtual private clouds with in the same or different aws regions.
 vpc peering allows you to connect to other vpc and share resources across them securily using private ip addresses.
Vpc ensure that route tables are configured to allow traffic between the vpcs.


VPC Endpoints ‚Äì Private connections between the VPC and AWS services (like S3, DynamoDB) without using the internet.


‚úÖ Real-time example:
In one project, I designed a VPC with public subnets for ALBs and bastion hosts, private subnets for 
EC2 application servers, and isolated subnets for RDS databases. We used NAT Gateway for outbound traffic, 
Security Groups for instance-level rules, and VPC Endpoints for private S3 access. This setup ensured both security and high availability.

So in short:
‚ÄúVPC is AWS‚Äôs private network where we control subnets, routing, and security. 
Its key components are subnets, IGW, NAT, route tables, security groups, NACLs, and endpoints, 
which together define how resources communicate securely inside and outside AWS.‚Äù
